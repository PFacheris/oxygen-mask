<%
  require 'json'
  require 'yaml'

  def task(name, file, binding)
    {
      task: name,
      config: YAML.load(ERB.new(File.read(file)).result(binding))
    }.to_json
  end

  def emit_datadog_metric(name, value)
    task(
      "emit-datadog-metric-#{name}",
      'tasks/emit_datadog_metric.yml.erb',
      binding
    )
  end
%>

resources:
- name: ((interval))
  type: time
  source:
    interval: ((interval))

- name: fly
  type: github-release
  check_every: 1h
  source:
    user: concourse
    repository: concourse
    access_token: ((concourse_github_dummy.access_token))

- name: oxygen-mask
  type: git
  source:
    uri: https://github.com/concourse/oxygen-mask

jobs:
- name: fly-hijack-failing-build
  build_logs_to_retain: 20
  serial: true
  plan:
  - get: ((interval))
    trigger: true
  - get: fly
    params:
      globs: [fly_linux_amd64]
  - task: trigger-and-wait-for-a-build
    config:
      image_resource:
        type: docker-image
        source:
          repository: ubuntu
      inputs:
      - name: fly
      params:
        ATC_URL: ((atc_url))
        TEAM_NAME: ((team_name))
        PIPELINE_NAME: ((pipeline_name))
        USERNAME: ((username))
        PASSWORD: ((password))

      platform: linux

      run:
        path: bash
        args:
        - -c
        - |
          #!/bin/bash

          set -e

          pushd fly
            chmod +x fly_linux_amd64
            mv fly_linux_amd64 fly
            export PATH=`pwd`:$PATH
          popd

          job_name="$PIPELINE_NAME/failing"

          fly -t ci login -c $ATC_URL -n $TEAM_NAME -u $USERNAME -p $PASSWORD -k
          fly -t ci trigger-job -j "$job_name" -w || true
          timeout 5 fly -t ci hijack \
            -j "$job_name" \
            -b $(fly -t ci builds -j "$job_name" | head -1 | awk '{print $3}') \
            echo Hello World

  on_failure: <%= emit_datadog_metric('concourse.fly_hijack_failing_build', 0) %>
  on_success: <%= emit_datadog_metric('concourse.fly_hijack_failing_build', 1) %>

- name: run-existing-pipeline
  build_logs_to_retain: 20
  serial: true
  plan:
  - get: ((interval))
    trigger: true
  - get: fly
    params:
      globs: [fly_linux_amd64]
  - task: trigger-and-wait-for-a-build
    config:
      image_resource:
        type: docker-image
        source:
          repository: ubuntu
      inputs:
      - name: fly
      params:
        ATC_URL: ((atc_url))
        TEAM_NAME: ((team_name))
        PIPELINE_NAME: ((pipeline_name))
        USERNAME: ((username))
        PASSWORD: ((password))

      platform: linux

      run:
        path: bash
        args:
        - -c
        - |
          #!/bin/bash

          set -e

          pushd fly
            chmod +x fly_linux_amd64
            mv fly_linux_amd64 fly
            export PATH=`pwd`:$PATH
          popd

          fly -t ci login -c $ATC_URL -n $TEAM_NAME -u $USERNAME -p $PASSWORD -k
          timeout 5 fly -t ci trigger-job -j "$PIPELINE_NAME/simple-job"
          timeout 60 fly -t ci watch -j "$PIPELINE_NAME/simple-job"
  on_failure: <%= emit_datadog_metric('concourse.run_existing_pipeline', 0) %>
  on_success: <%= emit_datadog_metric('concourse.run_existing_pipeline', 1) %>

- name: view-public-pipeline
  build_logs_to_retain: 20
  serial: true
  plan:
  - get: ((interval))
    trigger: true
  - task: check-pipeline-returns-known-string
    timeout: 15s
    config:
      image_resource:
        type: docker-image
        source:
          repository: justinribeiro/chrome-headless
      params:
        ATC_URL: ((atc_url))
        TEAM_NAME: ((team_name))
        PIPELINE_NAME: ((pipeline_name))

      platform: linux
      run:
        path: bash
        args:
          - -c
          - |
            #!/bin/bash
            set -eux

            url=$ATC_URL/teams/$TEAM_NAME/pipelines/$PIPELINE_NAME
            google-chrome-stable --timeout=1000 --no-sandbox --disable-gpu --headless --virtual-time-budget=1000 --dump-dom $url | grep -q simple-job
  on_failure: <%= emit_datadog_metric('concourse.view_public_pipeline', 0) %>
  on_success: <%= emit_datadog_metric('concourse.view_public_pipeline', 1) %>

- name: view-build-history
  build_logs_to_retain: 20
  serial: true
  plan:
  - get: ((interval))
    trigger: true
  - get: fly
    params:
      globs: [fly_linux_amd64]
  - task: check-build-history-is-viewable
    config:
      platform: linux

      image_resource:
        type: docker-image
        source:
          repository: justinribeiro/chrome-headless

      inputs:
      - name: fly

      params:
        ATC_URL: ((atc_url))
        TEAM_NAME: ((team_name))
        PIPELINE_NAME: ((pipeline_name))
        USERNAME: ((username))
        PASSWORD: ((password))

      run:
        user: root
        path: bash
        args:
        - -c
        - |
          #!/bin/bash

          set -e -u -x

          pushd fly
            chmod +x fly_linux_amd64
            mv fly_linux_amd64 fly
            export PATH=`pwd`:$PATH
          popd

          fly -t ci login -c $ATC_URL -n $TEAM_NAME -u $USERNAME -p $PASSWORD -k

          build_number=$(fly -t ci builds -j $PIPELINE_NAME/simple-job | head -n2 | tail -n1 | awk '{print $3}')

          url=$ATC_URL/teams/$TEAM_NAME/pipelines/$PIPELINE_NAME/jobs/simple-job/builds/$build_number
          google-chrome-stable --no-sandbox --disable-gpu --headless --timeout=1000 --virtual-time-budget=1000 --dump-dom "$url" | grep -q say-hello
  on_failure: <%= emit_datadog_metric('concourse.view_build_history', 0) %>
  on_success: <%= emit_datadog_metric('concourse.view_build_history', 1) %>

- name: create-and-run-new-pipeline
  build_logs_to_retain: 20
  serial: true
  plan:
  - get: ((interval))
    trigger: true
  - get: fly
    params:
      globs: [fly_linux_amd64]
  - get: oxygen-mask
  - task: create-and-run-new-pipeline
    config:
      platform: linux

      image_resource:
        type: docker-image
        source:
          repository: ubuntu

      inputs:
      - name: fly
      - name: oxygen-mask

      params:
        ATC_URL: ((atc_url))
        TEAM_NAME: ((team_name))
        PIPELINE_NAME: ((pipeline_name))
        USERNAME: ((username))
        PASSWORD: ((password))

      run:
        user: root
        path: timeout
        args:
        - 70
        - bash
        - -c
        - |
          #!/bin/bash

          set -e -u -x

          pushd fly
            chmod +x fly_linux_amd64
            mv fly_linux_amd64 fly
            export PATH=`pwd`:$PATH
          popd

          fly -t ci login -c $ATC_URL -n $TEAM_NAME -u $USERNAME -p $PASSWORD -k
          fly -t ci destroy-pipeline -n -p new-pipeline
          fly -t ci set-pipeline -n -p new-pipeline -c oxygen-mask/pipeline.yml
          fly -t ci unpause-pipeline -p new-pipeline

          until [ "$(fly -t ci builds -j new-pipeline/auto-triggering | wc -l)" -gt 0 ]; do
            echo 'waiting for job to trigger...'
            sleep 1
          done

          fly -t ci watch -j new-pipeline/auto-triggering
  on_failure: <%= emit_datadog_metric('concourse.create_and_run_new_pipeline', 0) %>
  on_success: <%= emit_datadog_metric('concourse.create_and_run_new_pipeline', 1) %>
